import streamlit as st
import os
import shutil
import json
import random
import time
from groq import Groq
from pydub import AudioSegment
from pydub.effects import normalize, high_pass_filter
from pydub.silence import detect_nonsilent
from faster_whisper import WhisperModel
import yt_dlp

# ==========================================
# âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(page_title="Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ù„Ø°ÙƒÙŠ (Context Aware)", page_icon="ğŸ§ ", layout="centered")

st.markdown("""
<div style="text-align: center;">
    <h1>ğŸ§  Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ (Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø°ÙƒÙŠ)</h1>
    <p>ÙŠÙÙ‡Ù… Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† "Ø§Ù„ÙˆØµÙ" Ùˆ"Ø§Ù„ÙØ¹Ù„" + ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù„ÙØ§Øª</p>
</div>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ› ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ù„ÙÙŠØ©
# ==========================================
SFX_DIR = "sfx_robust" 
if not os.path.exists(SFX_DIR): os.makedirs(SFX_DIR)

AudioSegment.converter = "ffmpeg" if shutil.which("ffmpeg") else "ffmpeg.exe"

api_key = st.secrets.get("GROQ_API_KEY")

# ==========================================
# ğŸ“š Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ (ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµØ±Ø®Ø§Øª Ø§Ù„Ø¨Ø´Ø±ÙŠØ© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£)
# ==========================================
SCENE_MAP = {
    "footsteps": ["footsteps on dirt cinematic", "slow horror walking footsteps"],
    "door_open": ["creaky door opening sound effect", "metal door slide heavy"],
    "door_slam": ["loud door slam reverb", "dungeon door close impact"],
    "breathing": ["scared heavy breathing isolated", "hyperventilation sound effect"],
    # Ù„Ø§Ø­Ø¸: Ø­Ø°ÙÙ†Ø§ "scream" ÙƒÙØ¦Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø®Ø·Ø£ØŒ ÙˆØ§Ø³ØªØ¨Ø¯Ù„Ù†Ø§Ù‡Ø§ Ø¨Ø£ØµÙˆØ§Øª Ø¨ÙŠØ¦ÙŠØ©
    "falling": ["body thud hitting ground", "heavy object fall impact"],
    "rock_crumble": ["cave debris falling sound", "earthquake rocks crumbling"],
    "heartbeat": ["horror heartbeat sound effect", "slow suspense pulse"],
    "wind": ["howling cave wind ambiance", "eerie wind whistle"],
    "silence": ["ear ringing tinnitus sound", "low suspense drone horror"],
    "glass": ["glass shattering loud sound", "window break crash"]
}

# ==========================================
# ğŸ§  Groq AI (Ø§Ù„Ø¯Ø³ØªÙˆØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯)
# ==========================================
def analyze_text_with_groq(text_data):
    if not api_key:
        st.error("âš ï¸ GROQ_API_KEY Ù…ÙÙ‚ÙˆØ¯!")
        return []

    client = Groq(api_key=api_key)
    
    # ğŸ‘‡ Ø§Ù„Ø¯Ø³ØªÙˆØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø®Ø±Ø¬:
    prompt = f"""
    You are a strictly logical sound editor for an audiobook.
    Analyze this Egyptian Arabic script: "{text_data}"

    CRITICAL RULES (Do NOT ignore):
    1. **Context is King:** If the narrator says "He screamed" (ØµØ±Ø®) or "He said loudly", **DO NOT** add a scream SFX. The narrator's voice IS the sound.
    2. **Environment Only:** Only add sounds the narrator CANNOT make (e.g., Door slam, Wind, Footsteps, Rocks falling, Heartbeat).
    3. **No Redundancy:** Do not double-up on sounds.
    4. **Spacing:** Keep at least 15 seconds between effects.
    5. **Selection:** Choose only the top 3-5 most essential environmental sounds.

    Available Effects Map: {list(SCENE_MAP.keys())}
    
    Return JSON array ONLY: 
    [{{"sfx": "category", "time": start_seconds, "duration": duration_seconds}}]
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0, # ØµÙØ± Ù„Ù„Ø¥Ù„ØªØ²Ø§Ù… Ø§Ù„ØªØ§Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯
            response_format={"type": "json_object"}
        )
        response_text = completion.choices[0].message.content
        parsed = json.loads(response_text)
        
        sfx_list = []
        if "sfx" in parsed: sfx_list = parsed["sfx"]
        elif isinstance(parsed, list): sfx_list = parsed
        else:
            for key in parsed:
                if isinstance(parsed[key], list): sfx_list = parsed[key]
        
        # ÙÙ„ØªØ± Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªØ¨Ø§Ø¹Ø¯
        filtered_list = []
        last_time = -20
        for item in sfx_list:
            if item['time'] - last_time > 15.0:
                filtered_list.append(item)
                last_time = item['time']
        
        return filtered_list

    except Exception as e:
        st.error(f"Groq Error: {e}")
        return []

# ==========================================
# ğŸ“¥ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ "Ø­Ø§Ø±Ø³ Ø§Ù„Ø¨ÙˆØ§Ø¨Ø©" (File Validator)
# ==========================================
def get_sfx_file(category):
    # 1. Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ù„ÙŠ
    existing_files = [f for f in os.listdir(SFX_DIR) if category in f]
    for file in existing_files:
        path = os.path.join(SFX_DIR, file)
        # ğŸ›¡ï¸ Ø§Ù„ÙØ­Øµ: Ù‡Ù„ Ø§Ù„Ù…Ù„Ù Ø­Ø¬Ù…Ù‡ Ù…Ù†Ø·Ù‚ÙŠØŸ (Ø£ÙƒØ¨Ø± Ù…Ù† 20KB)
        if os.path.getsize(path) > 20000:
            st.toast(f"âœ… Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø³Ù„ÙŠÙ…): {category}")
            return path
        else:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† ØµØºÙŠØ±Ø§Ù‹ (ÙØ§Ø±ØºØ§Ù‹)ØŒ Ø§Ø­Ø°ÙÙ‡
            try: os.remove(path) 
            except: pass

    # 2. Ø§Ù„ØªØ­Ù…ÙŠÙ„ (SoundCloud + YouTube)
    search_query = random.choice(SCENE_MAP.get(category, [category]))
    filename_base = f"{category}_{random.randint(100,999)}"
    filename_path = os.path.join(SFX_DIR, filename_base)

    st.toast(f"â¬‡ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {search_query}...")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø³Ø§ÙˆÙ†Ø¯ ÙƒÙ„Ø§ÙˆØ¯ (ØºØ§Ù„Ø¨Ø§Ù‹ Ø£Ù†Ø¬Ø­)
    ydl_opts_sc = {
        'format': 'bestaudio/best',
        'outtmpl': filename_path,
        'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'mp3'}],
        'quiet': True,
        'no_warnings': True,
        'max_filesize': 5*1024*1024,
        'match_filter': yt_dlp.utils.match_filter_func("duration < 90"),
    }
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© 1: SoundCloud
    try:
        with yt_dlp.YoutubeDL(ydl_opts_sc) as ydl:
            ydl.download([f"scsearch1:{search_query} sound effect"])
        final_path = filename_path + ".mp3"
        # ğŸ›¡ï¸ Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´: Ù‡Ù„ Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ù„Ù…Ù„Ù Ø³Ù„ÙŠÙ…ØŸ
        if os.path.exists(final_path) and os.path.getsize(final_path) > 20000:
            return final_path
    except: pass

    # Ù…Ø­Ø§ÙˆÙ„Ø© 2: YouTube (Android Mode)
    ydl_opts_yt = ydl_opts_sc.copy()
    ydl_opts_yt['extractor_args'] = {'youtube': {'player_client': ['android']}}
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts_yt) as ydl:
            ydl.download([f"ytsearch1:{search_query} sound effect no copyright"])
        final_path = filename_path + ".mp3"
        if os.path.exists(final_path) and os.path.getsize(final_path) > 20000:
            return final_path
    except: pass

    st.warning(f"âŒ ÙØ´Ù„ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø³Ù„ÙŠÙ… Ù„Ù€: {category}")
    return None

# ==========================================
# âœ‚ï¸ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
# ==========================================
def super_smart_crop(sound, desired_duration_sec):
    try:
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        nonsilent = detect_nonsilent(sound, min_silence_len=50, silence_thresh=-30)
        if nonsilent:
            start_trim = nonsilent[0][0]
            sound = sound[start_trim:]
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØª Ù„ÙŠØ³ Ù‚ØµÙŠØ±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹
        if len(sound) < 500: return None 

        desired_ms = int(desired_duration_sec * 1000)
        if len(sound) > desired_ms:
            sound = sound[:desired_ms]
            sound = sound.fade_out(200)
        return sound
    except:
        return sound

def process_audio(voice_file):
    st.info("ğŸ§  1. Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªÙ…Ø§Ø¹ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ØµØ©...")
    try:
        model = WhisperModel("medium", device="cpu", compute_type="int8")
        segments, _ = model.transcribe(voice_file, word_timestamps=True, language="ar")
        
        full_text = []
        clean_text = []
        for segment in segments:
            for word in segment.words:
                full_text.append(f"[{word.start:.2f}] {word.word}")
                clean_text.append(word.word)
        
        st.text_area("Ø§Ù„Ù†Øµ:", " ".join(clean_text), height=80)
        prompt_text = " ".join(full_text)
    except Exception as e:
        st.error(f"Whisper Error: {e}")
        return None

    st.info("ğŸ§  2. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ) ÙŠØ®ØªØ§Ø± Ø§Ù„Ù…Ø¤Ø«Ø±Ø§Øª...")
    sfx_plan = analyze_text_with_groq(prompt_text)
    
    if sfx_plan:
        st.success(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± {len(sfx_plan)} Ù…Ø¤Ø«Ø± Ø¨ÙŠØ¦ÙŠ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø± Ø§Ù„Ø³Ø±Ø¯).")
        st.write(sfx_plan)
    else:
        st.warning("âš ï¸ Ù„Ù… ÙŠØ¬Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø­Ø§Ø¬Ø© Ù„Ù…Ø¤Ø«Ø±Ø§Øª Ø¨ÙŠØ¦ÙŠØ© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø·Ø¹.")
        return None

    st.info("ğŸ¬ 3. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¯Ù…Ø¬ (ÙÙ‚Ø· Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø³Ù„ÙŠÙ…Ø©)...")
    full_audio = AudioSegment.from_file(voice_file)
    full_audio = normalize(high_pass_filter(full_audio, 80))
    
    progress = st.progress(0)
    for i, item in enumerate(sfx_plan):
        sfx_name = item.get("sfx")
        time_sec = float(item.get("time"))
        duration = float(item.get("duration", 2.0))
        
        sfx_path = get_sfx_file(sfx_name)
        
        if sfx_path: # ÙÙ‚Ø· Ø¥Ø°Ø§ Ø¹Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø± (ÙŠØ¹Ù†ÙŠ Ø§Ù„Ù…Ù„Ù Ø³Ù„ÙŠÙ…)
            try:
                sound = AudioSegment.from_file(sfx_path)
                sound = super_smart_crop(sound, duration)
                
                if sound: # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù‚Øµ Ù„Ù… ÙŠÙØ³Ø¯ Ø§Ù„Ù…Ù„Ù
                    sound = sound - 6 # Ø®ÙØ¶ Ø§Ù„ØµÙˆØª
                    full_audio = full_audio.overlay(sound, position=int(time_sec * 1000))
            except Exception as e:
                print(f"Merge Error: {e}")
        
        progress.progress((i + 1) / len(sfx_plan))

    output = "Final_Context_Montage.mp3"
    full_audio.export(output, format="mp3")
    return output

# ==========================================
# ğŸ–¥ï¸ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
# ==========================================
# Ø²Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ø§Ù„Ø¢Ù† Ù„Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ§Ø±ØºØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
if st.sidebar.button("ğŸ—‘ï¸ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙØ©"):
    if os.path.exists(SFX_DIR):
        shutil.rmtree(SFX_DIR)
        os.makedirs(SFX_DIR)
    st.sidebar.success("ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©!")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„ØµÙˆØª", type=["wav", "mp3"])

if uploaded_file:
    st.audio(uploaded_file)
    if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…ÙˆÙ†ØªØ§Ø¬ Ø§Ù„Ø°ÙƒÙŠ"):
        with open("input.mp3", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        final = process_audio("input.mp3")
        
        if final:
            st.balloons()
            st.audio(final)
            with open(final, "rb") as f:
                st.download_button("ØªØ­Ù…ÙŠÙ„", f, file_name="Cinema.mp3")
