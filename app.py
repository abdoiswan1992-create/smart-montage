import streamlit as st
import os
import shutil
import json
import random
import re
from groq import Groq
from pydub import AudioSegment
from pydub.effects import normalize, high_pass_filter
from pydub.silence import detect_nonsilent
from faster_whisper import WhisperModel
import yt_dlp

# ==========================================
# âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(page_title="Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ (AI Timer)", page_icon="â±ï¸", layout="centered")

st.markdown("""
<div style="text-align: center;">
    <h1>â±ï¸ Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ (Ø§Ù„Ù…Ù‚Øµ Ø§Ù„Ø²Ù…Ù†ÙŠ)</h1>
    <p>Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØ­Ø¯Ø¯ Ù…Ø¯Ø© ÙƒÙ„ Ù…Ø¤Ø«Ø± Ø¨Ø¯Ù‚Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ù‡Ø¯</p>
</div>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ› ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ù„ÙÙŠØ©
# ==========================================
SFX_DIR = "sfx_robust" 
if not os.path.exists(SFX_DIR): os.makedirs(SFX_DIR)

AudioSegment.converter = "ffmpeg" if shutil.which("ffmpeg") else "ffmpeg.exe"

api_key = st.secrets.get("GROQ_API_KEY")

SCENE_MAP = {
    "footsteps": ["running footsteps on dirt horror", "scared walking steps"],
    "door_open": ["creaky door open horror", "metal door slide"],
    "door_slam": ["loud door slam reverb", "impact thud sound"],
    "breathing": ["scared heavy breathing", "panic hyperventilation"],
    "scream": ["sharp gasp of fear", "shocked breath intake", "muffled scared noise"],
    "falling": ["body thud fall sound", "clothes rustling drop"],
    "rock_crumble": ["cave collapse debris", "falling rocks sound"],
    "heartbeat": ["intense slow heartbeat", "racing pulse sound"],
    "wind": ["eerie cave wind howling", "low frequency dark ambience"],
    "silence": ["high pitched ear ringing", "low suspense drone"],
    "glass": ["glass shattering cinematic", "window smash sound"]
}

# ==========================================
# ğŸ§  Groq AI (ÙŠØ­Ø¯Ø¯ Ø§Ù„ØªÙˆÙ‚ÙŠØª ÙˆØ§Ù„Ù…Ø¯Ø©)
# ==========================================
def analyze_text_with_groq(text_data):
    if not api_key:
        st.error("âš ï¸ GROQ_API_KEY Ù…ÙÙ‚ÙˆØ¯!")
        return []

    client = Groq(api_key=api_key)
    
    # Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¯Ø© (Duration)
    prompt = f"""
    Act as a sound editor. Analyze this Egyptian Arabic script:
    "{text_data}"

    Task: Identify sound effects AND their ideal duration based on context.
    
    Example: 
    - "He knocked quickly" -> Duration: 0.5s
    - "The door opened slowly" -> Duration: 3.0s
    
    Available Effects: {list(SCENE_MAP.keys())}
    
    Return JSON array ONLY: 
    [{{"sfx": "category", "time": start_seconds, "duration": duration_seconds}}]
    """

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        response_text = completion.choices[0].message.content
        parsed = json.loads(response_text)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù…Ø±ÙˆÙ†Ø©
        if "sfx" in parsed: return parsed["sfx"]
        if isinstance(parsed, list): return parsed
        for key in parsed:
            if isinstance(parsed[key], list): return parsed[key]
        return []
    except Exception as e:
        st.error(f"Groq Error: {e}")
        return []

# ==========================================
# ğŸ“¥ Ø§Ù„ØªØ­Ù…ÙŠÙ„
# ==========================================
def get_sfx_file(category):
    search_query = random.choice(SCENE_MAP.get(category, [category]))
    filename_base = f"{category}_{random.randint(100,999)}"
    filename_path = os.path.join(SFX_DIR, filename_base)
    
    existing = [f for f in os.listdir(SFX_DIR) if f.startswith(category)]
    if existing and random.random() > 0.4: 
        selected = os.path.join(SFX_DIR, random.choice(existing))
        if os.path.getsize(selected) > 5000: return selected

    st.toast(f"ğŸ¦… ØªØ­Ù…ÙŠÙ„: {search_query}...")
    
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': filename_path,
        'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'mp3'}],
        'quiet': True,
        'no_warnings': True,
        'max_filesize': 10*1024*1024,
        'match_filter': yt_dlp.utils.match_filter_func("duration < 60"),
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([f"ytsearch1:{search_query} sound effect no copyright"])
        return filename_path + ".mp3"
    except:
        if existing: return os.path.join(SFX_DIR, random.choice(existing))
        return None

# ==========================================
# âœ‚ï¸ Ø§Ù„Ù‚Øµ Ø§Ù„Ø°ÙƒÙŠ Ø¬Ø¯Ø§Ù‹ (Super Smart Crop)
# ==========================================
def super_smart_crop(sound, desired_duration_sec):
    try:
        # 1. Ø£ÙˆÙ„Ø§Ù‹: Ù†Ø­Ø°Ù Ø§Ù„ØµÙ…Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© (Trim Silence)
        # Ù†Ø³ØªØ®Ø¯Ù… Ø¹ØªØ¨Ø© Ø­Ø³Ø§Ø³Ø© (-30dB) Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¨Ø¯Ø¡ Ø§Ù„ØµÙˆØª ÙÙˆØ±Ø§Ù‹
        nonsilent = detect_nonsilent(sound, min_silence_len=50, silence_thresh=-30)
        
        if nonsilent:
            start_trim = nonsilent[0][0]
            sound = sound[start_trim:]
        
        # 2. Ø«Ø§Ù†ÙŠØ§Ù‹: Ù†Ø·Ø¨Ù‚ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„ØªÙŠ Ø·Ù„Ø¨Ù‡Ø§ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        desired_ms = int(desired_duration_sec * 1000)
        
        if len(sound) > desired_ms:
            # Ù‚Øµ Ø§Ù„Ø²Ø§Ø¦Ø¯
            sound = sound[:desired_ms]
            # Ø¹Ù…Ù„ Fade Out Ø³Ø±ÙŠØ¹ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„ÙƒÙŠ Ù„Ø§ ÙŠÙ†Ù‚Ø·Ø¹ Ø§Ù„ØµÙˆØª ÙØ¬Ø£Ø©
            sound = sound.fade_out(150)
        
        return sound
    except:
        return sound

# ==========================================
# ğŸ¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
# ==========================================
def process_audio(voice_file):
    st.info("ğŸ§  1. Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªÙ…Ø§Ø¹ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ØµØ©...")
    try:
        model = WhisperModel("medium", device="cpu", compute_type="int8")
        segments, _ = model.transcribe(voice_file, word_timestamps=True, language="ar")
        
        full_text = []
        clean_text = []
        for segment in segments:
            for word in segment.words:
                full_text.append(f"[{word.start:.2f}] {word.word}")
                clean_text.append(word.word)
        
        st.text_area("Ø§Ù„Ù†Øµ:", " ".join(clean_text), height=80)
        prompt_text = " ".join(full_text)
        
    except Exception as e:
        st.error(f"Whisper Error: {e}")
        return None

    st.info("â±ï¸ 2. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØ­Ø¯Ø¯ ØªÙˆÙ‚ÙŠØª ÙˆÙ…Ø¯Ø© ÙƒÙ„ Ù…Ø¤Ø«Ø±...")
    sfx_plan = analyze_text_with_groq(prompt_text)
    
    if sfx_plan:
        st.success(f"âœ… ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠØ· Ù„Ù€ {len(sfx_plan)} Ù…Ø¤Ø«Ø±!")
        st.write(sfx_plan) # Ø³ÙŠØ¹Ø±Ø¶ Ù„Ùƒ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù„ÙƒÙ„ ØµÙˆØª
    else:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ø¤Ø«Ø±Ø§Øª.")
        return None

    st.info("ğŸ¬ 3. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù‚Øµ ÙˆØ§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø¯Ù‚ÙŠÙ‚...")
    full_audio = AudioSegment.from_file(voice_file)
    full_audio = normalize(high_pass_filter(full_audio, 80))
    
    progress = st.progress(0)
    for i, item in enumerate(sfx_plan):
        sfx_name = item.get("sfx")
        time_sec = float(item.get("time"))
        # Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© 2 Ø«Ø§Ù†ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠØ­Ø¯Ø¯Ù‡Ø§ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        duration = float(item.get("duration", 2.0)) 
        
        sfx_path = get_sfx_file(sfx_name)
        
        if sfx_path and os.path.exists(sfx_path):
            try:
                sound = AudioSegment.from_file(sfx_path)
                
                # ğŸ‘‡ Ù‡Ù†Ø§ Ù†Ø·Ø¨Ù‚ Ø§Ù„Ù‚Øµ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                sound = super_smart_crop(sound, duration)
                
                # Ø®ÙØ¶ Ø§Ù„ØµÙˆØª
                sound = sound - 6
                
                full_audio = full_audio.overlay(sound, position=int(time_sec * 1000))
            except Exception as e:
                print(e)
        progress.progress((i + 1) / len(sfx_plan))

    output = "Final_Timed_Montage.mp3"
    full_audio.export(output, format="mp3")
    return output

# ==========================================
# ğŸ–¥ï¸ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
# ==========================================
if st.sidebar.button("ğŸ—‘ï¸ Ø­Ø°Ù Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"):
    if os.path.exists(SFX_DIR):
        shutil.rmtree(SFX_DIR)
        os.makedirs(SFX_DIR)
    st.sidebar.success("ØªÙ…!")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„ØµÙˆØª", type=["wav", "mp3"])

if uploaded_file:
    st.audio(uploaded_file)
    if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…ÙˆÙ†ØªØ§Ø¬ Ø§Ù„Ø¯Ù‚ÙŠÙ‚"):
        with open("input.mp3", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        final = process_audio("input.mp3")
        
        if final:
            st.balloons()
            st.audio(final)
            with open(final, "rb") as f:
                st.download_button("ØªØ­Ù…ÙŠÙ„", f, file_name="Timed_Montage.mp3")
